# -*- coding: utf-8 -*-
"""LAB7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bJe8InEdDbXjf9QqgMltitcKXrBON3RN
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

df=pd.read_csv('tblTrain.csv')
df

dfTest=pd.read_csv('tblTest.csv')
dfTest

item = {'Action': 'blue', 'Drama': 'red'}

plt.figure(figsize=(100,50))
# Create a scatter plot with different colors for each genre
for genre, color in item.items():
    gdata = dfTest[dfTest['Genre'] == genre]
    plt.scatter(gdata['Duration'], gdata['Rating'], c=color, label=genre, alpha=1)

# Annotating each point
for i, row in dfTest.iterrows():
    plt.annotate(row['Name'], (row['Duration'], row['Rating']),fontsize=15)


plt.xlabel('Duration')
plt.ylabel('Rating')
plt.title('Scatter Plot of Duration vs Rating of Trained Data')
plt.legend()
plt.grid(True)
plt.show

item = {'Action': 'blue', 'Drama': 'red'}

plt.figure(figsize=(100,50))
# Create a scatter plot with different colors for each genre
for genre, color in item.items():
    gdata = df[df['Genre'] == genre]
    plt.scatter(gdata['Duration'], gdata['Rating'], c=color, label=genre, alpha=1)

# Annotating each point
for i, row in df.iterrows():
    plt.annotate(row['Name'], (row['Duration'], row['Rating']),fontsize=15)


plt.xlabel('Duration')
plt.ylabel('Rating')
plt.title('Scatter Plot of Duration vs Rating of Test Data')
plt.legend()
plt.grid(True)
plt.show

"""Label Encoding to bring categorical data to numerical"""

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
df['Genre']=le.fit_transform(df['Genre'])
df['Genre'].unique()

df['Name']=le.fit_transform(df['Name'])
df['Name'].unique()

dfTest['Genre']=le.fit_transform(dfTest['Genre'])
dfTest['Genre'].unique()

dfTest['Name']=le.fit_transform(dfTest['Name'])
dfTest['Name'].unique()

X_test=dfTest.iloc[:,[0,1,3]].values
Y_test=dfTest.iloc[:,-2].values
X_train=df.iloc[:,[0,1,3]].values
Y_train=df.iloc[:,-2].values

"""feature scaling to the training and test set of independent variables for reducing the size to smaller values"""

#feature scaling
from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X_test=sc.fit_transform(X_test)
X_train=sc.fit_transform(X_train)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

#determining kvalues
knn_neighbors = np.arange(1, 500, 2).tolist()

confusion_matrices = []
accuracy_scores=[]
precision_scores=[]
recall_scores=[]
#fitting and evaluating model
for k in knn_neighbors:
  classifier = KNeighborsClassifier(k)
  classifier.fit(X_train,Y_train)
  Y_pred=classifier.predict(X_test)
  con_matrix=confusion_matrix(Y_test,Y_pred)
  confusion_matrices.append(con_matrix)

  accuracy = (con_matrix[0, 0] + con_matrix[1, 1]) / np.sum(con_matrix)
  recall = con_matrix[1, 1] / (con_matrix[1, 1] + con_matrix[1, 0])
  precision = con_matrix[1, 1] / (con_matrix[1, 1] + con_matrix[0, 1])

  accuracy_scores.append(accuracy)
  precision_scores.append(precision)
  recall_scores.append(recall)

#displaying confusion matrix for eack k
# for i, k in enumerate(knn_neighbors):
#     con_mat = ConfusionMatrixDisplay(confusion_matrix=confusion_matrices[i])
#     con_mat.plot(cmap='Blues')
#     plt.title(f'Confusion Matrix for k={k}')
#     print(f'Accuracy for k={k}: {accuracy_scores[i]:.2f}')
#     plt.show()

"""Plot"""

plt.plot(knn_neighbors, accuracy_scores, marker='.')
plt.title('Accuracy vs No. of Neighbors')
plt.xlabel('Number of Neighbors')
plt.ylabel('Accuracy')
plt.grid(True)
plt.show()

max_accuracy = max(accuracy_scores)
optimal_k = knn_neighbors[np.argmax(accuracy_scores)]

print(f'Optimal k: {optimal_k}')
print(f'Maximum Accuracy: {max_accuracy*100:.2f}')

k_value = 35
con_mat = ConfusionMatrixDisplay(confusion_matrix=confusion_matrices[k_value])
con_mat.plot(cmap='Blues')
plt.title(f'Confusion Matrix for k={k_value}')
plt.show()

precision = confusion_matrices[k_value][1, 1] / (confusion_matrices[k_value][1, 1] + confusion_matrices[k_value][0, 1])
print(f'Precision: {precision*100:.2f}')
recall = confusion_matrices[k_value][1, 1] / (confusion_matrices[k_value][1, 1] + confusion_matrices[k_value][1, 0])
print(f'Recall: {recall*100:.2f}')

m_recall=sum(recall_scores)/len(recall_scores)
m_precision=sum(precision_scores)/len(precision_scores)
print(f'Mean Recall:{m_recall*100:.2f}')
print(f'Mean Precision:{m_precision*100:.2f}')
fscore=2*((m_recall*m_precision)/(m_recall+m_precision))
print(f"F_Score:{fscore*100:.2f}")